"""
-------------------------------------------------------------------------------------
ESTUDO WEB SCRAPING SITE NBA PELA EQUIPE MÃO NO CÓDIGO
-------------------------------------------------------------------------------------
ETAPAS DO PROJETO:

1. Pegar conteúdo HTML a partir da URL
2. Parsear o conteúdo HTML - BeautifulSoup
3. Estruturar conteúdo em um Data Frame - Pandas
4. Transformar os Dados em um Dicionário de dados próprios
5. Converter e salvar em um arquivo JSON
"""
"""
-------------------------------------------------------------------------------------
PREPARAÇÕES ANTES DE ESCREVER OS CÓDIGOS
-------------------------------------------------------------------------------------

PREPARAÇÃO DO PYCHARM

pip install pymysql
pip freeze > requirements.txt               cria arquivo txt com LIBs
pip install pip-chill                       para salvar apenas as LIBS baixadas por mim e não as automáticas dos pacotes
pip-chill > requirements.txt                usar o pacote pip-chill no arquivo txt

BIBLIOTECAS (LIBS) PYTHON - PIP NO TERMINAL LOCAL PYCHARM:

pip install requests2
pip install pandas
pip install lxml
pip install beautifulsoup4
pip install selenium

DRIVES DOS NAVEGADORES:

Chrome: brew install chromodriver
Firefox: brew install geckodriver
"""
"""
-------------------------------------------------------------------------------------
IMPORTAR LIBS
-------------------------------------------------------------------------------------
"""

import time
import requests
import pandas as pd
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
import json

"""
-------------------------------------------------------------------------------------
1. Pegar conteúdo HTML a partir da URL
   INSTANCIAR O NAVEGADOR (Chrome ou Firefox)
-------------------------------------------------------------------------------------
"""
    # URL QUE IREMOS TRABALHAR

url = "https://www.nba.com/stats/players/traditional/?sort=PLAYER_NAME&dir=-1"

    # CRIANDO ESTRUTURA DE RANKINGS

top10ranking = {}
rankings = {
    '3points': {'field': 'FG3M', 'label':'3PM'},
    'points': {'field':'PTS', 'label': 'PTS'},
    'assistants': {'field':'AST', 'label':'AST'},
    'rebounds': {'field': 'REB', 'label': 'REB'},
    'steals': {'field': 'STL', 'label': 'STL'},
    'blocks': {'field': 'BLK', 'label': 'BLK'},
}

def buildrank (type):

    field = rankings[type]['field']
    label = rankings[type]['label']

    driver.find_element_by_xpath(
        f"//div[@class='nba-stat-table']//table//thead//tr//th[@data-field='{field}']").click()

    element = driver.find_element_by_xpath("//div[@class='nba-stat-table']//table")
    html_content = element.get_attribute('outerHTML')

    """
    -------------------------------------------------------------------------------------
    2. Parsear o conteúdo HTML - BeautifulSoup
       TRATAMENTO DOS DADOS
    -------------------------------------------------------------------------------------
    """

    soup = BeautifulSoup(html_content, 'html.parser')
    table = soup.find(name='table')

    """
    -------------------------------------------------------------------------------------
    3. Estruturar conteúdo em um Data Frame - Pandas
       ELIMINAR HTML E TRAZER APENAS DADOS
    -------------------------------------------------------------------------------------
    """

    df_full = pd.read_html(str(table))[0].head(10)
    df = df_full[['Unnamed: 0', 'PLAYER', 'AGE', 'TEAM', label]]
    df.columns = ['pos', 'player', 'age', 'team', 'total']

    """
    -------------------------------------------------------------------------------------
    4. Transformar os Dados em um Dicionário de dados próprios
       CRIAR DICIONÁRIO
    -------------------------------------------------------------------------------------
    """

    return df.to_dict('records')

option = Options()
option.headless = True
driver = webdriver.Chrome()  # Para ficar em background drive = webdriver.Chrome(options=option)

driver.get(url)

time.sleep(10)

driver.find_element_by_xpath(
    "//div[@class='banner-actions-container']//button[@id='onetrust-accept-btn-handler']").click()

time.sleep(5)

for k in rankings:
        top10ranking[k] = buildrank(k)

#print(top10ranking['points'])

driver.quit()

"""
-------------------------------------------------------------------------------------
5. Converter e salvar em um arquivo JSON
   CRIAR DICIONÁRIO
-------------------------------------------------------------------------------------
"""

js = json.dumps(top10ranking)
fp = open('ranking.json', 'w')
fp.write(js)
fp.close()
